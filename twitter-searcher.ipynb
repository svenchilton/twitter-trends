{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import twitter\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Import unquote to prevent url encoding errors in next_results\n",
    "# The urllib module is split into urllib.parse, urllib.request, \n",
    "# and urllib.error in Python 3\n",
    "# If running this in Python 2, change urllib.parse to urllib\n",
    "from urllib.parse import unquote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OAuth login function for instantiating Twitter API object\n",
    "def oauth_login():\n",
    "    # XXX: Go to http://twitter.com/apps/new to create an app and get values\n",
    "    # for these credentials that you'll need to provide in place of these\n",
    "    # empty string values that are defined as placeholders.\n",
    "    # See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = ''\n",
    "    CONSUMER_SECRET = ''\n",
    "    OAUTH_TOKEN = ''\n",
    "    OAUTH_TOKEN_SECRET = ''\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the up to 600 most recent tweets containing a given hashtag\n",
    "# The returned object contains a massive amount of data\n",
    "def find_tweets(hashtag):\n",
    "    # Ensure that the hashtag argument is a string\n",
    "    assert type(hashtag) == str, 'Argument hashtag must be a string'\n",
    "    # Ensure that the hashtag argument is, indeed, a hashtag \n",
    "    # in quotes, i.e. a string beginning with a pound sign\n",
    "    assert hashtag[0] == '#', 'hashtag string must begin with a #'\n",
    "    # Instantiate the Twitter API object \n",
    "    twitter_api = oauth_login()\n",
    "    # Begin searching the Twitter API for tweets containing hashtag\n",
    "    # Twitter only lets you find 100 tweets at a time \n",
    "    # (by default, the 100 most recent)\n",
    "    search_results = twitter_api.search.tweets(q=hashtag, count=100, result_type='recent')\n",
    "    \n",
    "    # Extract the information on the (up to) 100 most recent tweets\n",
    "    # as a list\n",
    "    statuses = search_results['statuses']\n",
    "    \n",
    "    # Iterate through 5 more batches of results by following the cursor \n",
    "    # back in time\n",
    "    for _ in range(5):\n",
    "        #print(\"Length of statuses\", len(statuses))\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        # The as statement is required in Python 3  \n",
    "        # A comma would be required instead for Python 2.5 and earlier  \n",
    "        # Python 2.6 and 2.7 support both the comma and the as statement\n",
    "        except KeyError as e: # No more results when next_results doesn't exist\n",
    "            break\n",
    "        \n",
    "        # Create a dictionary from next_results, which has the following form:\n",
    "        # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "        kwargs = dict([kv.split('=') for kv in unquote(next_results[1:]).split(\"&\") ])    \n",
    "        \n",
    "        # Search for the 100 next most recent tweets\n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        # Append the results of the last search to the statuses list\n",
    "        statuses += search_results['statuses']\n",
    "        \n",
    "    return statuses\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resample/re-bin the time stamps to get a count of the tweets\n",
    "# by time interval, which will vary by the the difference between\n",
    "# the first and last time stamps\n",
    "def resample_time_stamps(time_df):\n",
    "    # Ensure that time_df is a DataFrame\n",
    "    # The assert statement looks like this because \n",
    "    # we imported pandas as pd\n",
    "    assert type(time_df) == pd.core.frame.DataFrame, 'Argument must be a pandas DataFrame'\n",
    "    \n",
    "    # Determine the range of times\n",
    "    diff_year   = abs(time_index[0].year   - time_index[-1].year)\n",
    "    diff_month  = abs(time_index[0].month  - time_index[-1].month)\n",
    "    diff_day    = abs(time_index[0].day    - time_index[-1].day)\n",
    "    diff_hour   = abs(time_index[0].hour   - time_index[-1].hour)\n",
    "    diff_minute = abs(time_index[0].minute - time_index[-1].minute)\n",
    "    diff_second = abs(time_index[0].second - time_index[-1].second)\n",
    "    # Use the range of times to resample the data, \n",
    "    # and thus determine the plot format\n",
    "    # Perhaps adjust this later\n",
    "    if diff_year > 0:\n",
    "        # Resample/bucket by month\n",
    "        # The fillna(0) command fills any bins with NaN in them with 0s\n",
    "        time_df = time_df.resample('M', how='sum').fillna(0)\n",
    "        bin_width = 'month'\n",
    "    elif diff_month > 0:\n",
    "        if diff_month > 4:\n",
    "            # Resample by week\n",
    "            time_df = time_df.resample('W', how='sum').fillna(0)\n",
    "            bin_width = 'week'\n",
    "        else: \n",
    "            # Resample by day\n",
    "            time_df = time_df.resample('D', how='sum').fillna(0)\n",
    "            bin_width = 'day'\n",
    "    elif diff_day > 0:\n",
    "        if diff_day <= 10:\n",
    "            # Resample by hour\n",
    "            time_df = time_df.resample('H', how='sum').fillna(0)\n",
    "            bin_width = 'hour'\n",
    "        elif diff_day <= 21:\n",
    "            # Resample by 6 hours\n",
    "            time_df = time_df.resample('6H', how='sum').fillna(0)\n",
    "            bin_width = '6 hours'\n",
    "        else: \n",
    "            # Resample by day\n",
    "            time_df = time_df.resample('D', how='sum').fillna(0)\n",
    "            bin_width = 'day'\n",
    "    elif diff_hour > 0:\n",
    "        if diff_hour <= 3:\n",
    "            # Resample by minute\n",
    "            time_df = time_df.resample('T', how='sum').fillna(0)\n",
    "            bin_width = 'minute'\n",
    "        elif diff_hour <= 12:\n",
    "            # Resample by 5 minutes\n",
    "            time_df = time_df.resample('5T', how='sum').fillna(0)\n",
    "            bin_width = '5 minutes'\n",
    "        else: \n",
    "            # Resample by 10 minutes\n",
    "            time_df = time_df.resample('10T', how='sum').fillna(0)\n",
    "            bin_width = '10 minutes'\n",
    "    elif diff_minute > 0:\n",
    "        if diff_minute <= 3:\n",
    "            # Resample by second\n",
    "            time_df = time_df.resample('S', how='sum').fillna(0)\n",
    "            bin_width = 'second'\n",
    "        elif diff_minute <= 12:\n",
    "            # Resample by 5 seconds\n",
    "            time_df = time_df.resample('5S', how='sum').fillna(0)\n",
    "            bin_width = '5 seconds'\n",
    "        else: \n",
    "            # Resample by 10 seconds\n",
    "            time_df = time_df.resample('10S', how='sum').fillna(0)\n",
    "            bin_width = '10 seconds'\n",
    "    elif abs(time_index[0].second - time_index[-1].second) > 0:\n",
    "        # Resample/bucket (reorder) by second\n",
    "        time_df = time_df.resample('S', how='sum').fillna(0)\n",
    "        bin_width = 'second'\n",
    "    else: \n",
    "        # Resample/bucket (reorder) by second\n",
    "        time_df = time_df.resample('S', how='sum').fillna(0)\n",
    "        bin_width = 'second'\n",
    "    \n",
    "    return time_df, bin_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the time distribution of the (up to) 600 \n",
    "# most recent tweets containing the desired hashtag\n",
    "# Also returns a DataFrame containing the times \n",
    "# and locations (if available) of the tweets\n",
    "def map_tweets(hashtag):\n",
    "    # Ensure that the hashtag argument is a string\n",
    "    assert type(hashtag) == str, 'Argument hashtag must be a string'\n",
    "    # Ensure that the hashtag argument is, indeed, a hashtag \n",
    "    # in quotes, i.e. a string beginning with a pound sign\n",
    "    assert hashtag[0] == '#', 'hashtag string must begin with a #'\n",
    "    \n",
    "    # Get all the data on the most recent tweets\n",
    "    statuses = find_tweets(hashtag)\n",
    "    \n",
    "    # Initialize and populate a NumPy array with \n",
    "    # the time stamps of the tweets contained in \n",
    "    # statuses, in reverse chronological order\n",
    "    time_stamps = np.array([])\n",
    "    for i in range(len(statuses)):\n",
    "        time_stamps = np.append(time_stamps, statuses[i]['created_at'])\n",
    "    \n",
    "    # Initialize and populate a NumPy array with \n",
    "    # the coordinates of the tweets contained in \n",
    "    # statuses, if available\n",
    "    coordinates = np.array([])\n",
    "    for i in range(len(statuses)):\n",
    "        coordinates = np.append(coordinates, statuses[i]['coordinates'])\n",
    "    \n",
    "    # Create an array of ones for every tweet\n",
    "    ones_array = np.ones(len(time_stamps))\n",
    "    # Create a Pandas DatetimeIndex of the time stamps\n",
    "    time_index = pd.DatetimeIndex(time_stamps)\n",
    "    # Create a Pandas DataFrame showing one tweet \n",
    "    # for each time stamp\n",
    "    time_df = pd.DataFrame(ones_array, index=time_index, columns=['Tweets'])\n",
    "    # Create a DataFrame associating a location with \n",
    "    # each time stamp, if available\n",
    "    coord_df = pd.DataFrame(coordinates, index=time_index, columns=['Coordinates'])\n",
    "    \n",
    "    # Resample the DataFrame time_df\n",
    "    time_df, bin_width = resample_time_stamps(time_df)\n",
    "    \n",
    "    # Create the plot\n",
    "    time_plot = time_df.plot(legend=False)\n",
    "    time_plot.set_xlabel('Date/Time')\n",
    "    time_plot.set_ylabel('Tweets per '+bin_width)\n",
    "    time_plot.set_title('Frequency of tweets containing hashtag '+hashtag)\n",
    "    \n",
    "    return time_plot, coord_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
